# Data Engineering with AWS Course

## Program Details

During this program, students will complete four courses and five projects. Throughout the projects, students will play the part of a data engineer at a music streaming company. They'll work with the same type of data in each project, but with increasing data volume, velocity, and complexity. Here's a course-by-course breakdown:

### Course 1 – Data Modeling

In this course, students will learn to create relational and NoSQL data models to fit the diverse needs of data consumers. In the project, students will build SQL (Postgres) and NoSQL (Apache Cassandra) data models using user activity data for a music streaming app.

### Course 2 – Cloud Data Warehouses

In this course, students will learn to create cloud-based data warehouses. In the project, students will build an ELT pipeline that extracts data from Amazon S3, stages it in Amazon Redshift, and transforms it into a set of dimensional tables.

### Course 3 – Data Lakes with Apache Spark

In this course, students will learn more about the big data ecosystem, how to work with massive datasets with Apache Spark, and how to store big data in a data lake. In the project, students will build an ETL pipeline for a data lake using Apache Spark and S3.

### Course 4 – Data Pipelines with Apache Airflow

In this course, students will learn to schedule, automate, and monitor data pipelines using Apache Airflow. In the project, they'll continue your work on the music streaming company's data infrastructure by creating and automating a set of data pipelines.

---

*Note: This is an archive of the Data Engineering with AWS course. For the most up-to-date information and resources, please refer to the original course materials on Udacity or AWS's official documentation.*
